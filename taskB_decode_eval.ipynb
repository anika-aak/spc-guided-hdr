{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e9eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from utils.common import DATA_ROOT\n",
    "\n",
    "class HDRTrainTriplet(Dataset):\n",
    "    \"\"\"\n",
    "    CMOS (RGB, full res), SPC (mono, half res), GT_HDR (RGB full res).\n",
    "    Paired by identical filename stems.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cmos_dir = (\n",
    "            DATA_ROOT\n",
    "            / \"Training_1024x512\"\n",
    "            / \"CMOS_sat_1024x512\"\n",
    "            / \"dynamic_exposures_train_png_1024x512\"\n",
    "        )\n",
    "\n",
    "        self.spc_dir = (\n",
    "            DATA_ROOT\n",
    "            / \"Training_1024x512\"\n",
    "            / \"SPC_512x256_train_png\"\n",
    "        )\n",
    "\n",
    "        self.gt_dir = (\n",
    "            DATA_ROOT\n",
    "            / \"GT_HDR_1024X512_train_png\"\n",
    "        )\n",
    "\n",
    "        self.to_rgb = T.ToTensor()\n",
    "        self.to_gray = T.ToTensor()\n",
    "\n",
    "        self.items = self._pair_lists()\n",
    "\n",
    "    def _pair_lists(self):\n",
    "        cmos_files = {\n",
    "            Path(f).stem: self.cmos_dir / f\n",
    "            for f in os.listdir(self.cmos_dir)\n",
    "            if f.lower().endswith(\".png\")\n",
    "        }\n",
    "        spc_files = {\n",
    "            Path(f).stem: self.spc_dir / f\n",
    "            for f in os.listdir(self.spc_dir)\n",
    "            if f.lower().endswith(\".png\")\n",
    "        }\n",
    "        gt_files = {\n",
    "            Path(f).stem: self.gt_dir / f\n",
    "            for f in os.listdir(self.gt_dir)\n",
    "            if f.lower().endswith(\".png\")\n",
    "        }\n",
    "\n",
    "        common = sorted(set(cmos_files) & set(spc_files) & set(gt_files))\n",
    "        if not common:\n",
    "            raise RuntimeError(\"No matching CMOS/SPC/GT triplets found\")\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"name\": stem,\n",
    "                \"cmos_path\": cmos_files[stem],\n",
    "                \"spc_path\":  spc_files[stem],\n",
    "                \"gt_path\":   gt_files[stem],\n",
    "            }\n",
    "            for stem in common\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.items[idx]\n",
    "\n",
    "        cmos_img = Image.open(e[\"cmos_path\"]).convert(\"RGB\")\n",
    "        spc_img  = Image.open(e[\"spc_path\"]).convert(\"L\")\n",
    "        gt_img   = Image.open(e[\"gt_path\"]).convert(\"RGB\")\n",
    "\n",
    "        cmos_t = self.to_rgb(cmos_img)   # (3,512,1024)\n",
    "        spc_t  = self.to_gray(spc_img)   # (1,256,512)\n",
    "        gt_t   = self.to_rgb(gt_img)     # (3,512,1024)\n",
    "\n",
    "        return {\n",
    "            \"name\": e[\"name\"],\n",
    "            \"cmos\": cmos_t,\n",
    "            \"spc\": spc_t,\n",
    "            \"gt\": gt_t,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550ebd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 5 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from utils.common import DEVICE, RECON_DIR\n",
    "from models.feature_extractors import DilatedConvEncoder, HighResCMOSEncoder\n",
    "from models.decoder import SmallDecoder\n",
    "from models.fusion import SimpleFusion\n",
    "from utils.metrics import mse_loss, psnr, ssim\n",
    "from utils.viz import save_panel\n",
    "from utils.save_intermediate import tensor_to_pngimg\n",
    "from pathlib import Path\n",
    "\n",
    "# Use the dataset with CMOS, SPC, and GT HDR\n",
    "full_train = HDRTrainTriplet()\n",
    "subset_ids = list(range(min(5, len(full_train))))  # use 5 samples to debug\n",
    "subset = Subset(full_train, subset_ids)\n",
    "loader = DataLoader(subset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"Subset size:\", len(subset), \"Device:\", DEVICE)\n",
    "\n",
    "spc_encoder  = DilatedConvEncoder(in_channels=1).to(DEVICE).eval()\n",
    "cmos_encoder = HighResCMOSEncoder().to(DEVICE).eval()\n",
    "fusion_head  = SimpleFusion().to(DEVICE)\n",
    "decoder      = SmallDecoder(in_channels=6).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fusion_head.fuse_conv.weight.zero_()\n",
    "    fusion_head.fuse_conv.bias.zero_()\n",
    "    eye = torch.eye(3).view(3,3,1,1)\n",
    "    fusion_head.fuse_conv.weight[:, :3] = eye\n",
    "\n",
    "\n",
    "params = list(fusion_head.parameters()) + list(decoder.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c07675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate adjusted to: 0.005000\n",
      "[epoch 50/600] avg MSE: 0.018118\n",
      "Learning rate adjusted to: 0.005000\n",
      "[epoch 100/600] avg MSE: 0.015765\n",
      "Learning rate adjusted to: 0.005000\n",
      "[epoch 150/600] avg MSE: 0.014501\n",
      "Learning rate adjusted to: 0.005000\n",
      "[epoch 200/600] avg MSE: 0.013085\n",
      "Learning rate adjusted to: 0.002500\n",
      "[epoch 250/600] avg MSE: 0.011285\n",
      "Learning rate adjusted to: 0.002500\n",
      "[epoch 300/600] avg MSE: 0.012057\n",
      "Learning rate adjusted to: 0.002500\n",
      "[epoch 350/600] avg MSE: 0.010235\n",
      "Learning rate adjusted to: 0.002500\n",
      "[epoch 400/600] avg MSE: 0.009873\n",
      "Learning rate adjusted to: 0.001250\n",
      "[epoch 450/600] avg MSE: 0.009598\n",
      "Learning rate adjusted to: 0.001250\n",
      "[epoch 500/600] avg MSE: 0.009331\n",
      "Learning rate adjusted to: 0.001250\n",
      "[epoch 550/600] avg MSE: 0.009516\n",
      "Learning rate adjusted to: 0.001250\n",
      "[epoch 600/600] avg MSE: 0.009132\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 600 # start with 50; you can reduce to 10 for quick tests\n",
    "for ep in range(EPOCHS):\n",
    "    running = 0.0\n",
    "    for batch in loader:\n",
    "        cmos = batch[\"cmos\"].to(DEVICE)\n",
    "        spc  = batch[\"spc\"].to(DEVICE)\n",
    "        gt   = batch[\"gt\"].to(DEVICE)\n",
    "\n",
    "        # Extract features (frozen)\n",
    "        with torch.no_grad():\n",
    "            cmos_feat = cmos_encoder(cmos)\n",
    "            spc_feat  = spc_encoder(spc)\n",
    "\n",
    "        fused_feat = fusion_head(cmos_feat, spc_feat)\n",
    "        decoder_in = torch.cat([fused_feat, cmos], dim=1) \n",
    "        pred = decoder(decoder_in).clamp(0,1)\n",
    "\n",
    "        loss = mse_loss(pred, gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item()\n",
    "    if (ep+1) % 50 == 0:\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Learning rate adjusted to: {current_lr:.6f}\")\n",
    "        print(f\"[epoch {ep+1}/{EPOCHS}] avg MSE: {running/len(loader):.6f}\")\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5854ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL] 9C4A0001-5e832da4cc: MSE=0.002270, PSNR=26.44, SSIM=0.7350\n",
      "       recon -> outputs\\reconstructions\\9C4A0001-5e832da4cc_recon.png\n",
      "       panel -> outputs\\visuals_for_review\\9C4A0001-5e832da4cc_panel.png\n",
      "[EVAL] 9C4A0001-beb39950ec: MSE=0.005068, PSNR=22.95, SSIM=0.7169\n",
      "       recon -> outputs\\reconstructions\\9C4A0001-beb39950ec_recon.png\n",
      "       panel -> outputs\\visuals_for_review\\9C4A0001-beb39950ec_panel.png\n",
      "[EVAL] 9C4A0001-6fbef8172f: MSE=0.009346, PSNR=20.29, SSIM=0.7910\n",
      "       recon -> outputs\\reconstructions\\9C4A0001-6fbef8172f_recon.png\n",
      "       panel -> outputs\\visuals_for_review\\9C4A0001-6fbef8172f_panel.png\n",
      "[EVAL] 9C4A0001-c6c6bf7c76: MSE=0.022056, PSNR=16.56, SSIM=0.6274\n",
      "       recon -> outputs\\reconstructions\\9C4A0001-c6c6bf7c76_recon.png\n",
      "       panel -> outputs\\visuals_for_review\\9C4A0001-c6c6bf7c76_panel.png\n",
      "[EVAL] 9C4A0001-7c62497929: MSE=0.005467, PSNR=22.62, SSIM=0.7659\n",
      "       recon -> outputs\\reconstructions\\9C4A0001-7c62497929_recon.png\n",
      "       panel -> outputs\\visuals_for_review\\9C4A0001-7c62497929_panel.png\n",
      "       GT -> outputs\\reconstructions\\9C4A0001-7c62497929_GT.png\n"
     ]
    }
   ],
   "source": [
    "decoder.eval()\n",
    "fusion_head.eval()\n",
    "\n",
    "results_table = []\n",
    "for batch in loader:\n",
    "    name = batch[\"name\"][0]\n",
    "    cmos = batch[\"cmos\"].to(DEVICE)\n",
    "    spc  = batch[\"spc\"].to(DEVICE)\n",
    "    gt   = batch[\"gt\"].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cmos_feat = cmos_encoder(cmos)\n",
    "        spc_feat  = spc_encoder(spc)\n",
    "        fused_feat = fusion_head(cmos_feat, spc_feat)\n",
    "        decoder_in = torch.cat([fused_feat, cmos], dim=1)  # (1,6,H,W)\n",
    "        pred = decoder(decoder_in).clamp(0, 1)\n",
    "\n",
    "    mse_val  = mse_loss(pred, gt).item()\n",
    "    psnr_val = psnr(pred, gt, max_val=1.0)\n",
    "    ssim_val = ssim(pred, gt)\n",
    "\n",
    "    results_table.append((name, mse_val, psnr_val, ssim_val))\n",
    "\n",
    "    recon_img = tensor_to_pngimg(pred[0].cpu())\n",
    "    recon_path = RECON_DIR / f\"{name}_recon.png\"\n",
    "    recon_img.save(recon_path)\n",
    "    gt_img = tensor_to_pngimg(gt[0].cpu())\n",
    "    gt_path = RECON_DIR / f\"{name}_GT.png\"\n",
    "    gt_img.save(gt_path)\n",
    "\n",
    "\n",
    "    panel_path = save_panel(\n",
    "        cmos[0].cpu(),\n",
    "        spc[0].cpu(),\n",
    "        gt[0].cpu(),\n",
    "        pred[0].cpu(),\n",
    "        name\n",
    "    )\n",
    "\n",
    "    print(f\"[EVAL] {name}: MSE={mse_val:.6f}, PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\")\n",
    "    print(f\"       recon -> {recon_path}\")\n",
    "    print(f\"       panel -> {panel_path}\")\n",
    "\n",
    "results_table\n",
    "\n",
    "from utils.save_intermediate import tensor_to_pngimg\n",
    "\n",
    "gt_img = tensor_to_pngimg(gt[0].cpu())\n",
    "gt_out_path = RECON_DIR / f\"{name}_GT.png\"\n",
    "gt_img.save(gt_out_path)\n",
    "print(\"       GT ->\", gt_out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb19428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean/std: 0.0010192279005423188 0.03301551565527916\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        cmos_feat = cmos_encoder(batch[\"cmos\"].to(DEVICE))\n",
    "        spc_feat  = spc_encoder(batch[\"spc\"].to(DEVICE))\n",
    "        fused_feat = fusion_head(cmos_feat, spc_feat)\n",
    "        print(\"Feature mean/std:\", fused_feat.mean().item(), fused_feat.std().item())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f03afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT HDR min/max/mean: 0.0 1.0 0.12313276802013118\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "sample_path = list((DATA_ROOT / \"GT_HDR_1024X512_train_png\").glob(\"*.png\"))[0]\n",
    "arr = np.asarray(Image.open(sample_path)) / 255.0\n",
    "print(\"GT HDR min/max/mean:\", arr.min(), arr.max(), arr.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddea318",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
