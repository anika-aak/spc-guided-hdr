{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc73bea6",
   "metadata": {},
   "source": [
    "# Task A: Independent Feature Extraction (CMOS vs SPC)\n",
    "\n",
    "Goal for mid-term:\n",
    "1. Take paired frames from:\n",
    "   - CMOS_sat_1024x512 (saturated RGB camera)\n",
    "   - SPC_512x256_train_png (SPC sensor, HDR-ish mono)\n",
    "2. Run separate feature extractors:\n",
    "   - CMOS branch (pretrained backbone) → 3-channel feature map\n",
    "   - SPC branch (dilated conv) → 3-channel feature map\n",
    "3. Save:\n",
    "   - Raw CMOS frame\n",
    "   - Raw SPC frame\n",
    "   - CMOS feature map\n",
    "   - SPC feature map\n",
    "\n",
    "This demonstrates:\n",
    "- We can learn/produce meaningful feature representations per sensor.\n",
    "- We are treating CMOS and SPC as two separate input modalities.\n",
    "- We are **not** resizing SPC and **not** fusing yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e042ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "Torch built with CUDA: 12.1\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torch built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7dce0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41826ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\anika\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys, torch\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebb7643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "Total samples: 2100\n",
      "Example: 9C4A0001-5e832da4cc\n",
      "CMOS shape: torch.Size([3, 512, 1024])\n",
      "SPC shape: torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.dataset\n",
    "importlib.reload(utils.dataset)\n",
    "from utils.dataset import HDRPairDataset\n",
    "\n",
    "ds = HDRPairDataset()\n",
    "print(\"Total samples:\", len(ds))\n",
    "s = ds[0]\n",
    "print(\"Example:\", s[\"name\"])\n",
    "print(\"CMOS shape:\", s[\"cmos\"].shape)\n",
    "print(\"SPC shape:\", s[\"spc\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad10fd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "Device: cuda\n",
      "Subset size: 5\n",
      "Saving Task A outputs to: outputs\\taskA_outputs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from utils.dataset import HDRPairDataset\n",
    "from utils.common import DEVICE, OUT_ROOT\n",
    "from models.feature_extractors import DilatedConvEncoder\n",
    "from models.feature_extractors import HighResCMOSEncoder\n",
    "from utils.save_intermediate import tensor_to_pngimg, save_feature_map\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Load full dataset (CMOS + SPC only)\n",
    "full_train = HDRPairDataset()\n",
    "\n",
    "# We'll just take a few for demo/export\n",
    "subset_idx = list(range(min(5, len(full_train))))\n",
    "subset = Subset(full_train, subset_idx)\n",
    "loader = DataLoader(subset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Subset size:\", len(subset))\n",
    "\n",
    "# Feature extractors\n",
    "spc_encoder = DilatedConvEncoder(in_channels=1).to(DEVICE).eval()\n",
    "cmos_encoder = HighResCMOSEncoder().to(DEVICE).eval()\n",
    "\n",
    "# Output directory for review artifacts\n",
    "TASKA_OUT = OUT_ROOT / \"taskA_outputs\"\n",
    "TASKA_OUT.mkdir(exist_ok=True)\n",
    "print(\"Saving Task A outputs to:\", TASKA_OUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f0e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 9C4A0001-5e832da4cc\n",
      "CMOS shape: torch.Size([3, 512, 1024])\n",
      "SPC shape: torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "s0 = full_train[0]\n",
    "print(\"name:\", s0[\"name\"])\n",
    "print(\"CMOS shape:\", s0[\"cmos\"].shape)\n",
    "print(\"SPC shape:\",  s0[\"spc\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7662814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9C4A0001-5e832da4cc]\n",
      "  CMOS raw: outputs\\taskA_outputs\\9C4A0001-5e832da4cc_CMOSraw.png\n",
      "  SPC raw: outputs\\taskA_outputs\\9C4A0001-5e832da4cc_SPCraw.png\n",
      "  CMOS feat: outputs\\feat_cmos\\9C4A0001-5e832da4cc_CMOSfeat_feat.png\n",
      "  SPC feat: outputs\\feat_spc\\9C4A0001-5e832da4cc_SPCfeat_feat.png\n",
      "[9C4A0001-6fbef8172f]\n",
      "  CMOS raw: outputs\\taskA_outputs\\9C4A0001-6fbef8172f_CMOSraw.png\n",
      "  SPC raw: outputs\\taskA_outputs\\9C4A0001-6fbef8172f_SPCraw.png\n",
      "  CMOS feat: outputs\\feat_cmos\\9C4A0001-6fbef8172f_CMOSfeat_feat.png\n",
      "  SPC feat: outputs\\feat_spc\\9C4A0001-6fbef8172f_SPCfeat_feat.png\n",
      "[9C4A0001-7c62497929]\n",
      "  CMOS raw: outputs\\taskA_outputs\\9C4A0001-7c62497929_CMOSraw.png\n",
      "  SPC raw: outputs\\taskA_outputs\\9C4A0001-7c62497929_SPCraw.png\n",
      "  CMOS feat: outputs\\feat_cmos\\9C4A0001-7c62497929_CMOSfeat_feat.png\n",
      "  SPC feat: outputs\\feat_spc\\9C4A0001-7c62497929_SPCfeat_feat.png\n",
      "[9C4A0001-beb39950ec]\n",
      "  CMOS raw: outputs\\taskA_outputs\\9C4A0001-beb39950ec_CMOSraw.png\n",
      "  SPC raw: outputs\\taskA_outputs\\9C4A0001-beb39950ec_SPCraw.png\n",
      "  CMOS feat: outputs\\feat_cmos\\9C4A0001-beb39950ec_CMOSfeat_feat.png\n",
      "  SPC feat: outputs\\feat_spc\\9C4A0001-beb39950ec_SPCfeat_feat.png\n",
      "[9C4A0001-c6c6bf7c76]\n",
      "  CMOS raw: outputs\\taskA_outputs\\9C4A0001-c6c6bf7c76_CMOSraw.png\n",
      "  SPC raw: outputs\\taskA_outputs\\9C4A0001-c6c6bf7c76_SPCraw.png\n",
      "  CMOS feat: outputs\\feat_cmos\\9C4A0001-c6c6bf7c76_CMOSfeat_feat.png\n",
      "  SPC feat: outputs\\feat_spc\\9C4A0001-c6c6bf7c76_SPCfeat_feat.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        name = batch[\"name\"][0]\n",
    "\n",
    "        # Per-sensor tensors\n",
    "        cmos = batch[\"cmos\"].to(DEVICE)  # (1,3,512,1024)\n",
    "        spc  = batch[\"spc\"].to(DEVICE)   # (1,1,256,512)\n",
    "\n",
    "        # Separate feature extraction branches\n",
    "        cmos_feat = cmos_encoder(cmos)   # (1,3,512,1024) after upsample in backbone\n",
    "        spc_feat  = spc_encoder(spc)     # (1,3,256,512)\n",
    "\n",
    "        # Save feature maps\n",
    "        cmos_feat_path = save_feature_map(cmos_feat, name + \"_CMOSfeat\", mode=\"cmos\")\n",
    "        spc_feat_path  = save_feature_map(spc_feat,  name + \"_SPCfeat\",  mode=\"spc\")\n",
    "\n",
    "        # Save raw CMOS frame (RGB)\n",
    "        cmos_raw_img = tensor_to_pngimg(batch[\"cmos\"][0].cpu())\n",
    "        cmos_raw_path = TASKA_OUT / f\"{name}_CMOSraw.png\"\n",
    "        cmos_raw_img.save(cmos_raw_path)\n",
    "\n",
    "        # Save raw SPC frame\n",
    "        spc_tiled = batch[\"spc\"][0].repeat(3,1,1).cpu()          # make it RGB-looking\n",
    "        spc_raw_img = tensor_to_pngimg(spc_tiled)\n",
    "        spc_raw_path = TASKA_OUT / f\"{name}_SPCraw.png\"\n",
    "        spc_raw_img.save(spc_raw_path)\n",
    "\n",
    "        print(f\"[{name}]\")\n",
    "        print(\"  CMOS raw:\",  cmos_raw_path)\n",
    "        print(\"  SPC raw:\",   spc_raw_path)\n",
    "        print(\"  CMOS feat:\", cmos_feat_path)\n",
    "        print(\"  SPC feat:\",  spc_feat_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fba7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9C4A0001-5e832da4cc] fused -> outputs\\fused\\9C4A0001-5e832da4cc_FUSEDfeat.png\n",
      "[9C4A0001-6fbef8172f] fused -> outputs\\fused\\9C4A0001-6fbef8172f_FUSEDfeat.png\n",
      "[9C4A0001-7c62497929] fused -> outputs\\fused\\9C4A0001-7c62497929_FUSEDfeat.png\n",
      "[9C4A0001-beb39950ec] fused -> outputs\\fused\\9C4A0001-beb39950ec_FUSEDfeat.png\n",
      "[9C4A0001-c6c6bf7c76] fused -> outputs\\fused\\9C4A0001-c6c6bf7c76_FUSEDfeat.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.fusion import SimpleFusion\n",
    "from utils.save_intermediate import _tensor_to_pngimg  # we'll use internal helper\n",
    "from utils.common import OUT_ROOT\n",
    "from pathlib import Path\n",
    "\n",
    "# where we'll save fused maps\n",
    "FUSED_OUT = OUT_ROOT / \"fused\"\n",
    "FUSED_OUT.mkdir(exist_ok=True)\n",
    "\n",
    "fusion_head = SimpleFusion().to(DEVICE).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        name = batch[\"name\"][0]\n",
    "\n",
    "        # forward both encoders\n",
    "        cmos = batch[\"cmos\"].to(DEVICE)  # (1,3,512,1024)\n",
    "        spc  = batch[\"spc\"].to(DEVICE)   # (1,1,256,512)\n",
    "\n",
    "        cmos_feat = cmos_encoder(cmos)   # (1,3,512,1024)\n",
    "        spc_feat  = spc_encoder(spc)     # (1,3,256,512)\n",
    "\n",
    "        # fuse\n",
    "        fused_feat = fusion_head(cmos_feat, spc_feat)  # (1,3,512,1024)\n",
    "\n",
    "        # save fused feature map as PNG\n",
    "        fused_img = _tensor_to_pngimg(fused_feat.cpu()[0])\n",
    "        fused_path = FUSED_OUT / f\"{name}_FUSEDfeat.png\"\n",
    "        fused_img.save(fused_path)\n",
    "\n",
    "        print(f\"[{name}] fused -> {fused_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be7aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
